{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phone-Plan-Recommender\n",
    "---\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. In this notebook, multiple models are trained and tested in order to determine which will have the highest accuracy for this task.  In this project, the threshold for accuracy is 0.75. \n",
    "\n",
    "The following Scikit-Learn models will be tested:\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forest \n",
    "\n",
    "\n",
    "A \"sanity check\" will also be performed. An accuracy score will be determined for the baseline of just predicting randomly. That score, which represents random chance, should be surpassed by the trained models and provides a valuable reference point for evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Necessary Packages \n",
    "\n",
    "# Data Prep Packages \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Model Assessment Package \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been read in as df.\n"
     ]
    }
   ],
   "source": [
    "# Load in data \n",
    "try:\n",
    "    # Attempt to read the data\n",
    "    df = pd.read_csv('datasets/users_behavior.csv')\n",
    "    # If successful, print Confirmation\n",
    "    print(\"The data has been read in as df.\")\n",
    "except Exception as e:\n",
    "    # If an error occurs, print an error message\n",
    "    print(\"Error reading data:\", e)\n",
    "    print(\"To get all project files please visit https://github.com/le-crupi64/Phone-Plan-Recommender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Assess data \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "---\n",
    "The data has already been cleaned: there are no null values or duplicated rows and all columns are the appropriate data type. The following steps will be taken to prepare the data to be used with the models:\n",
    "1. Split the data into training(75% of data) and validating(25% of data) data sets \n",
    "2. Split both the training set and the validating set into features and target. The is_ultra column is the target and the other columns are the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validating sets \n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Split the training set into features and target \n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# Split the Validation set into features and target \n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Establishing the Baseline of Chance \n",
    "---\n",
    "The is_ultra target is a boolean value, so a random classifier baseline will be established. The accuracy score will be determined for chance predictions, providing an additional metric for assessing models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Classifier Baseline Accuracy on Validation Set: 0.5559701492537313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate class distribution from the training set\n",
    "class_distribution = target_train.value_counts(normalize=True).values\n",
    "\n",
    "# Generate random predictions for the validation set based on the class distribution\n",
    "num_instances_valid = len(target_valid)\n",
    "random_predictions_valid = np.random.choice([0, 1], size=num_instances_valid, p=class_distribution)\n",
    "\n",
    "# Calculate accuracy of the random predictions\n",
    "accuracy_valid = accuracy_score(target_valid, random_predictions_valid)\n",
    "print(\"Random Classifier Baseline Accuracy on Validation Set:\", accuracy_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.74149377593361\n",
      "Accuracy of the logistic regression model on the validation set: 0.753731343283582\n"
     ]
    }
   ],
   "source": [
    "# Set Up Model\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "# train model on training set\n",
    "model.fit(features_train, target_train)  \n",
    "\n",
    "# Generate predictions for training and validation sets\n",
    "predictions_train = model.predict(features_train)\n",
    "predictions_valid = model.predict(features_valid)\n",
    "\n",
    "# Calculate accuracy scores using accuracy_score()\n",
    "accuracy_train = accuracy_score(target_train, predictions_train)\n",
    "accuracy_valid = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "print(\"Accuracy of the logistic regression model on the training set:\", accuracy_train)\n",
    "print(\"Accuracy of the logistic regression model on the validation set:\", accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Overview**\n",
    "\n",
    "The accuracy for the training set is approximately 74% and the accuracy for the validation set is approximately 75%. The first just falling short of the .75 threshold for accuracy established for this project and the second right at the threshold. This model was more accurate than the sanity check by 0.18656716417, or approximately 19%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Decision Tree model on the training set:  0.8688796680497926\n",
      "Accuracy of the best Decision Tree model on the validation set:  0.7898009950248757\n",
      "The Decision Tree model with the highest accuracy had a max depth of:  7\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to hold info on the model with the highest accuracy\n",
    "best_model = None\n",
    "accuracy_best = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Loop through various max depths to establish which produces the model with the highest accuracy \n",
    "for depth in range(1, 10):\n",
    "\tmodel = DecisionTreeClassifier(random_state=12345, max_depth= depth)\n",
    "\t\n",
    "\t# train the model\n",
    "\tmodel.fit(features_train, target_train)\n",
    "\t# get the model's predictions\n",
    "\tpredictions_valid = model.predict(features_valid) \n",
    "\tpredictions_train = model.predict(features_train)\n",
    "\t# calculate the accuracy\n",
    "\taccuracy_train = accuracy_score(target_train, predictions_train)\n",
    "\tresult = accuracy_score(target_valid, predictions_valid) \n",
    "\n",
    "\t# Compare new accuracy to previous highest accuracy\n",
    "\tif result > accuracy_best:\n",
    "\t\tbest_model = model\n",
    "\t\taccuracy_best = result\n",
    "\t\tbest_depth = depth\n",
    "        \n",
    "print(\"Accuracy of the best Decision Tree model on the training set: \", accuracy_train)\n",
    "print(\"Accuracy of the best Decision Tree model on the validation set: \", accuracy_best)\n",
    "print(\"The Decision Tree model with the highest accuracy had a max depth of: \", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Results Overview***\n",
    "\n",
    "The model performs better on the training set (accuracy of 0.8689) compared to the validation set (accuracy of 0.7898). This suggests slight overfitting. Both accuracies exceed the  .75 threshold for accuracy established for this project. This model was more accurate than the sanity check by 0.22263681592, or approximately 22%. The model with the highest accuracy has a maximum depth of 7. This suggests that the model is relatively complex, as it has a depth of 7 in its decision tree structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best random forrest model on the training set:  0.9800829875518672\n",
      "Accuracy of the best random forrest model on the validation set:  0.7860696517412935\n",
      "The random forrest model with the highest accuracy had a max depth of:  9\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to hold info on the model with the highest accuracy\n",
    "best_model = None\n",
    "accuracy_best = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Loop through various max depths to establish which produces the model with the highest accuracy \n",
    "for est in range(1, 10):\n",
    "\tmodel = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "\t\n",
    "\t# train the model\n",
    "\tmodel.fit(features_train, target_train)\n",
    "\t# get the model's predictions\n",
    "\tpredictions_valid = model.predict(features_valid) \n",
    "\tpredictions_train = model.predict(features_train)\n",
    "\t# calculate the accuracy\n",
    "\taccuracy_train = accuracy_score(target_train, predictions_train)\n",
    "\tresult = accuracy_score(target_valid, predictions_valid) \n",
    "\n",
    "\t# Compare new accuracy to previous highest accuracy\n",
    "\tif result > accuracy_best:\n",
    "\t\tbest_model = model\n",
    "\t\taccuracy_best = result\n",
    "\t\tbest_depth = depth\n",
    "        \n",
    "print(\"Accuracy of the best random forrest model on the training set: \", accuracy_train)\n",
    "print(\"Accuracy of the best random forrest model on the validation set: \", accuracy_best)\n",
    "print(\"The random forrest model with the highest accuracy had a max depth of: \", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Results Overview***\n",
    "\n",
    "The model performs better on the training set (accuracy of 0.98) compared to the validation set (accuracy of 0.786). This suggests overfitting. Both accuracies exceed the  .75 threshold for accuracy established for this project. This model was more accurate than the sanity check by 0.21890547263, or approximately 22%. The model with the highest accuracy has a maximum depth of 9. This suggests that the model is relatively complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
